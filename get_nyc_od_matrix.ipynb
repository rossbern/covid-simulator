{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas_access as mdb\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "################################\n",
    "# Taxi data (May 2009)\n",
    "# https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "################################\n",
    "\n",
    "# Read in taxi data for May 2009\n",
    "tlc = pd.read_csv('data/yellow_tripdata_2009-05.csv', \n",
    "                 usecols=['Trip_Pickup_DateTime', 'Passenger_Count', 'Start_Lon', 'Start_Lat',\n",
    "                          'End_Lon', 'End_Lat'])\n",
    "\n",
    "# Keep only weekdays\n",
    "tlc.Trip_Pickup_DateTime = pd.to_datetime(tlc.Trip_Pickup_DateTime)\n",
    "tlc = tlc.loc[tlc.Trip_Pickup_DateTime.dt.dayofweek <= 4, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brinaseidel/anaconda3/lib/python3.6/site-packages/geopandas/tools/sjoin.py:61: UserWarning: CRS of frames being joined does not match!(None != epsg:4326)\n",
      "  \"(%s != %s)\" % (left_df.crs, right_df.crs)\n",
      "/Users/brinaseidel/anaconda3/lib/python3.6/site-packages/geopandas/tools/sjoin.py:61: UserWarning: CRS of frames being joined does not match!(None != epsg:4326)\n",
      "  \"(%s != %s)\" % (left_df.crs, right_df.crs)\n"
     ]
    }
   ],
   "source": [
    "# Read in census tracts\n",
    "census_tracts = gpd.read_file('data/2000 Census Tracts/geo_export_21ca0b77-873c-4bfe-89c0-462b6aad1ea4.shp')\n",
    "\n",
    "# Merge in census tract for starting info\n",
    "start_geometry = [Point(xy) for xy in zip(tlc.Start_Lon, tlc.Start_Lat)]\n",
    "gdf = gpd.GeoDataFrame(tlc,  geometry=start_geometry)\n",
    "merged_file = gpd.sjoin(gdf, census_tracts, how='left', op='within')\n",
    "tlc = pd.DataFrame(merged_file)\n",
    "# Add county codes\n",
    "tlc.loc[tlc.boro_name == \"Manhattan\", \"ct2000\"] = \"061\" + tlc.loc[tlc.boro_name == \"Manhattan\", \"ct2000\"]\n",
    "tlc.loc[tlc.boro_name == \"Queens\", \"ct2000\"] = \"081\" + tlc.loc[tlc.boro_name == \"Queens\", \"ct2000\"]\n",
    "tlc.loc[tlc.boro_name == \"Brooklyn\", \"ct2000\"] = \"047\" + tlc.loc[tlc.boro_name == \"Brooklyn\", \"ct2000\"]\n",
    "tlc.loc[tlc.boro_name == \"Bronx\", \"ct2000\"] = \"005\" + tlc.loc[tlc.boro_name == \"Bronx\", \"ct2000\"]\n",
    "tlc.loc[tlc.boro_name == \"Staten Island\", \"ct2000\"] = \"085\" + tlc.loc[tlc.boro_name == \"Staten Island\", \"ct2000\"]\n",
    "tlc = tlc[['Trip_Pickup_DateTime', 'Passenger_Count', 'Start_Lon', 'Start_Lat', 'End_Lon', 'End_Lat',  'ct2000']]\n",
    "tlc.columns = ['Trip_Pickup_DateTime', 'Passenger_Count', 'Start_Lon', 'Start_Lat', 'End_Lon', 'End_Lat', 'start_ct2000']\n",
    "\n",
    "# Merge in census tract for destination info\n",
    "end_geometry = [Point(xy) for xy in zip(tlc.End_Lon, tlc.End_Lat)]\n",
    "gdf = gpd.GeoDataFrame(tlc,  geometry=end_geometry)\n",
    "merged_file = gpd.sjoin(gdf, census_tracts, how='left', op='within')\n",
    "tlc = pd.DataFrame(merged_file)\n",
    "# Add county codes\n",
    "tlc.loc[tlc.boro_name == \"Manhattan\", \"ct2000\"] = \"061\" + tlc.loc[tlc.boro_name == \"Manhattan\", \"ct2000\"]\n",
    "tlc.loc[tlc.boro_name == \"Queens\", \"ct2000\"] = \"081\" + tlc.loc[tlc.boro_name == \"Queens\", \"ct2000\"]\n",
    "tlc.loc[tlc.boro_name == \"Brooklyn\", \"ct2000\"] = \"047\" + tlc.loc[tlc.boro_name == \"Brooklyn\", \"ct2000\"]\n",
    "tlc.loc[tlc.boro_name == \"Bronx\", \"ct2000\"] = \"005\" + tlc.loc[tlc.boro_name == \"Bronx\", \"ct2000\"]\n",
    "tlc.loc[tlc.boro_name == \"Staten Island\", \"ct2000\"] = \"085\" + tlc.loc[tlc.boro_name == \"Staten Island\", \"ct2000\"]\n",
    "tlc = tlc[['Trip_Pickup_DateTime', 'Passenger_Count', 'Start_Lon', 'Start_Lat', 'End_Lon', 'End_Lat','start_ct2000', 'ct2000']]\n",
    "tlc.columns = ['Trip_Pickup_DateTime', 'Passenger_Count', 'Start_Lon', 'Start_Lat', 'End_Lon', 'End_Lat', 'start_ct2000', 'end_ct2000']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brinaseidel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Get average hourly passenger counts by start-end tuple\n",
    "tlc['hour'] = tlc.Trip_Pickup_DateTime.dt.hour\n",
    "tlc = tlc.groupby([\"start_ct2000\",  \"end_ct2000\", \"hour\"])['Passenger_Count'].sum().reset_index()\n",
    "# Average across all weekdays in the month\n",
    "tlc.Passenger_Count = tlc.Passenger_Count/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltrips_short_exp123_wkdy_final_noXYcoord\n",
      "ltrips_short_exp13_sat_final_noXYcoord\n",
      "ltrips_short_exp13_sun_final_noXYcoord\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# MTA Data (May-Nov 2008)\n",
    "# http://web.mta.info/mta/planning/data-nyc-travel.html#\n",
    "################################\n",
    "\n",
    "# Read in the MTA origin-destination survey data\n",
    "for tbl in mdb.list_tables(\"data/NYCSurvey_TripFiles_noXYcoord.mdb\"):\n",
    "    print(tbl)\n",
    "mta = mdb.read_table(\"data/NYCSurvey_TripFiles_noXYcoord.mdb\", \"ltrips_short_exp123_wkdy_final_noXYcoord\", converters_from_schema=False)\n",
    "\n",
    "# Use trip-level weights (EXP32_FINAL_WKD) as person counts\n",
    "mta = mta[['EXP32_FINAL_WKD', 'dtime','trip_sdate', 'O_TRACT', 'D_TRACT']]\n",
    "\n",
    "# Format census tracts to get six digits\n",
    "mta.D_TRACT = mta.D_TRACT.apply(str).str.zfill(13)\n",
    "mta.D_TRACT = mta.D_TRACT.str.slice(2, 11)\n",
    "mta.O_TRACT = mta.O_TRACT.apply(str).str.zfill(13)\n",
    "mta.O_TRACT = mta.O_TRACT.str.slice(2, 11)\n",
    "\n",
    "# Get hour\n",
    "mta['hour'] = mta.dtime.str.slice(0,2).apply(int)\n",
    "\n",
    "# Get hourly sums by start-end tuple\n",
    "mta = mta.groupby(['O_TRACT', 'D_TRACT', 'hour']).EXP32_FINAL_WKD.sum().reset_index()\n",
    "mta.EXP32_FINAL_WKD = mta.EXP32_FINAL_WKD/5 # these are weekday approximations; we want daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "mta.columns = ['origin_tract', 'dest_tract', 'hour', 'mta_trips']\n",
    "tlc.columns = ['origin_tract', 'dest_tract', 'hour', 'tlc_trips']\n",
    "trips = mta.merge(tlc, on=['origin_tract', 'dest_tract', 'hour'], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_tract</th>\n",
       "      <th>dest_tract</th>\n",
       "      <th>hour</th>\n",
       "      <th>mta_trips</th>\n",
       "      <th>tlc_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>001000403</td>\n",
       "      <td>081129101</td>\n",
       "      <td>16</td>\n",
       "      <td>190.366778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001001100</td>\n",
       "      <td>061022000</td>\n",
       "      <td>16</td>\n",
       "      <td>17.680145</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>001001100</td>\n",
       "      <td>081002900</td>\n",
       "      <td>9</td>\n",
       "      <td>158.542912</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>001001100</td>\n",
       "      <td>081009900</td>\n",
       "      <td>16</td>\n",
       "      <td>61.459843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>001005900</td>\n",
       "      <td>047003300</td>\n",
       "      <td>11</td>\n",
       "      <td>119.420210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1341415</td>\n",
       "      <td>085032300</td>\n",
       "      <td>085022600</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1341416</td>\n",
       "      <td>085032300</td>\n",
       "      <td>085030302</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1341417</td>\n",
       "      <td>085032300</td>\n",
       "      <td>085032300</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1341418</td>\n",
       "      <td>085032300</td>\n",
       "      <td>085032300</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1341419</td>\n",
       "      <td>085032300</td>\n",
       "      <td>085032300</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1341420 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        origin_tract dest_tract  hour   mta_trips  tlc_trips\n",
       "0          001000403  081129101    16  190.366778        NaN\n",
       "1          001001100  061022000    16   17.680145        NaN\n",
       "2          001001100  081002900     9  158.542912        NaN\n",
       "3          001001100  081009900    16   61.459843        NaN\n",
       "4          001005900  047003300    11  119.420210        NaN\n",
       "...              ...        ...   ...         ...        ...\n",
       "1341415    085032300  085022600    19         NaN   0.095238\n",
       "1341416    085032300  085030302     4         NaN   0.047619\n",
       "1341417    085032300  085032300     0         NaN   0.190476\n",
       "1341418    085032300  085032300     1         NaN   0.047619\n",
       "1341419    085032300  085032300    21         NaN   0.142857\n",
       "\n",
       "[1341420 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to pickle\n",
    "pickle.dump(trips, open( \"data/trips_long.p\", \"wb\" ) )\n",
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get daily total trips\n",
    "daily_total = trips.groupby(['origin_tract', 'dest_tract'])[['mta_trips', 'tlc_trips']].sum().reset_index()\n",
    "daily_total = daily_total.fillna(0)\n",
    "daily_total['trips'] = daily_total.mta_trips + daily_total.tlc_trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P0030001: Total population\n",
    "params = {\"key\": \"7530e2501288a8dfb28803342f5d1493cf00cb96\",\n",
    "          \"state\": \"36\",   # New York\n",
    "          \"county\": \"061,047,005,085,081\",  #New York County (Manhattan), Kings County (Brooklyn), Bronx County (The Bronx), Richmond County (Staten Island), and Queens County (Queens)\n",
    "          \"indicators\": \"P001001\"\n",
    "         }\n",
    "url = \"https://api.census.gov/data/2000/sf1?get=\"+params[\"indicators\"]+\"&for=tract:*&in=state:\"+params[\"state\"]+\"&in=county:\"+params[\"county\"]+\"&key=\"+params[\"key\"]\n",
    "response = requests.get(url, data = {'key':'value'})\n",
    "colnames = response.json()[0]\n",
    "colnames[0] = \"population\"\n",
    "population = response.json()[1:]\n",
    "population = pd.DataFrame(population, columns=colnames)\n",
    "population.tract = population.county + population.tract # Add county code\n",
    "population = population[['population', 'tract']]\n",
    "population.population = population.population.apply(int)\n",
    "# Drop areas with no population\n",
    "population = population.loc[population.population != 0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross join population with itself to make a long version of the origin-destination matrix\n",
    "population['key']  = 0\n",
    "od_long = population.merge(population, on='key', how='outer')\n",
    "od_long = od_long[['tract_x', 'tract_y', 'population_x']]\n",
    "od_long.columns = ['origin_tract', 'dest_tract', 'population']\n",
    "\n",
    "# Keep population only for cases where origin=destination (diagonal of OD matrix)\n",
    "od_long.loc[od_long.origin_tract != od_long.dest_tract, 'population'] = 0\n",
    "\n",
    "# Subtract total pop that leaves each origin tract during the day\n",
    "pop_leaving = daily_total.groupby('origin_tract').trips.sum().reset_index()\n",
    "od_long = od_long.merge(pop_leaving, on='origin_tract', how='left')\n",
    "od_long.loc[od_long.origin_tract == od_long.dest_tract, 'population'] = od_long.loc[od_long.origin_tract == od_long.dest_tract, 'population'] - od_long.loc[od_long.origin_tract == od_long.dest_tract, 'trips'] \n",
    "od_long.drop(['trips'], axis=1, inplace=True)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in pop moving from each origin to each destination\n",
    "od_long = od_long.merge(daily_total, on=['origin_tract', 'dest_tract'], how='left')\n",
    "od_long.loc[od_long.origin_tract != od_long.dest_tract, 'population'] =  od_long.loc[od_long.origin_tract != od_long.dest_tract, 'trips'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "od = od_long.pivot(index='origin_tract', columns='dest_tract', values='population').reset_index().fillna(0)\n",
    "# Add one to every cell for smoothing purposes\n",
    "od[od.columns[1:]] = od[od.columns[1:]]  + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save origin-destination matrix\n",
    "pickle.dump(od, open( \"data/nyc_od.p\", \"wb\" ) )\n",
    "od.drop(\"origin_tract\", axis=1).to_csv(\"data/nyc_od.csv\", index=False, header=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
